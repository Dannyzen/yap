<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Yap Monitor</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        .fade-in {
            animation: fadeIn 0.3s ease-in;
        }

        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: translateY(10px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .mic-active {
            box-shadow: 0 0 15px rgba(239, 68, 68, 0.5);
        }
    </style>
</head>

<body class="bg-gray-900 text-gray-100 font-sans min-h-screen flex flex-col items-center p-6">

    <div class="w-full max-w-3xl">
        <header class="flex justify-between items-center mb-6 border-b border-gray-700 pb-4">
            <div>
                <h1
                    class="text-3xl font-bold bg-gradient-to-r from-blue-400 to-purple-500 bg-clip-text text-transparent">
                    âš¡ Yap
                </h1>
                <p class="text-gray-400 text-sm mt-1">Yet Another Pipe - Voice Client</p>
            </div>
            <div id="status"
                class="flex items-center space-x-2 px-3 py-1 rounded-full bg-red-900/30 text-red-400 border border-red-800 transition-all duration-300">
                <span class="w-2 h-2 rounded-full bg-current animate-pulse"></span>
                <span class="text-xs font-bold tracking-wide uppercase">Disconnected</span>
            </div>
        </header>

        <main class="space-y-6">
            <div id="controls" class="flex flex-col items-center gap-4">
                <button id="connectBtn" onclick="toggleConnection()"
                    class="bg-blue-600 hover:bg-blue-500 text-white font-semibold py-3 px-8 rounded-lg transition-all shadow-lg hover:shadow-blue-500/20 active:scale-95 w-full max-w-xs flex justify-center items-center gap-2">
                    Start Microphone
                </button>
            </div>

            <div id="transcript-container"
                class="bg-gray-800/50 rounded-xl p-6 min-h-[400px] max-h-[70vh] overflow-y-auto border border-gray-700 shadow-xl space-y-4 relative">
                <div class="text-center text-gray-500 italic mt-20" id="placeholder">
                    Click Start to begin transcription...
                </div>
                <!-- Transcripts appear here -->
            </div>
        </main>

        <footer class="mt-8 text-gray-500 text-xs text-center">
            Yap Server v1.0
        </footer>
    </div>

    <script>
        let ws = null;
        let audioCtx = null;
        let mediaStream = null;
        let scriptProcessor = null;

        const statusEl = document.getElementById('status');
        const connectBtn = document.getElementById('connectBtn');
        const container = document.getElementById('transcript-container');
        const placeholder = document.getElementById('placeholder');

        function setStatus(state) {
            const config = {
                disconnected: { text: "Disconnected", color: "red" },
                connecting: { text: "Connecting...", color: "yellow" },
                connected: { text: "Recording", color: "green" }
            };
            const c = config[state];
            statusEl.className = `flex items-center space-x-2 px-3 py-1 rounded-full bg-${c.color}-900/30 text-${c.color}-400 border border-${c.color}-800 transition-all duration-300`;
            statusEl.querySelector('span:last-child').innerText = c.text;

            if (state === 'connected') {
                connectBtn.innerText = "Stop Microphone";
                connectBtn.classList.add('animate-pulse');
                connectBtn.classList.replace('bg-blue-600', 'bg-red-600');
                connectBtn.classList.replace('hover:bg-blue-500', 'hover:bg-red-500');
                if (placeholder) placeholder.style.display = 'none';
            } else {
                connectBtn.innerText = "Start Microphone";
                connectBtn.classList.remove('animate-pulse');
                connectBtn.classList.replace('bg-red-600', 'bg-blue-600');
                connectBtn.classList.replace('hover:bg-red-500', 'hover:bg-blue-500');
            }
        }

        function toggleConnection() {
            if (ws) {
                stopConnection();
            } else {
                startConnection();
            }
        }

        async function startConnection() {
            setStatus('connecting');

            try {
                await startAudioCapture();
            } catch (e) {
                console.error("Audio capture failed:", e);
                alert("Could not access microphone: " + e.message);
                setStatus('disconnected');
                return;
            }

            ws = new WebSocket("ws://localhost:9090");

            ws.onopen = () => {
                console.log("Connected");
                // Send Handshake for Transcription
                const handshake = {
                    uid: generateUUID(),
                    language: "en",
                    task: "transcribe",
                    model: "small",
                    use_vad: true
                };
                ws.send(JSON.stringify(handshake));
            };

            ws.onmessage = (event) => {
                try {
                    const data = JSON.parse(event.data);

                    if (data.message === "SERVER_READY") {
                        handleReady("Microphone Active - Speak Now!");
                    } else if (data.segments) {
                        const uid = data.uid || "local";
                        if (data.segments.length > 0) {
                            const lastSeg = data.segments[data.segments.length - 1];
                            updateTranscriptDisplay(uid, lastSeg);
                        }
                    }
                } catch (e) {
                    console.error("Error processing message:", e);
                }
            };

            ws.onclose = () => {
                stopAudioCapture();
                ws = null;
                setStatus('disconnected');
            };

            ws.onerror = (e) => {
                console.error(e);
                stopConnection();
            };
        }

        function stopConnection() {
            if (ws) {
                ws.close();
                ws = null;
            }
            stopAudioCapture();
            setStatus('disconnected');
        }

        function handleReady(msg) {
            setStatus('connected');
            console.log("Ready");
            document.getElementById('placeholder').innerHTML = `
                <div class="animate-pulse text-blue-400 font-medium">
                    ${msg}<br>
                    <span class="text-xs text-gray-500 font-normal">
                        Streaming audio to server...
                    </span>
                </div>
            `;
        }

        // --- Audio Capture Logic ---
        async function startAudioCapture() {
            // Request standard audio
            mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });

            // Create Context
            // We do NOT pass sampleRate here because on some OS/Browsers (Like Linux PulseAudio),
            // opening a context at a rate different from hardware causes a crash or error.
            // We will handle resampling manually in the scriptProcessor.
            try {
                audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            } catch (e) {
                console.error("Failed to create AudioContext", e);
                throw e;
            }

            const source = audioCtx.createMediaStreamSource(mediaStream);

            // Use ScriptProcessor for raw data access (worklet is better but harder in single file)
            // Buffer size 4096 is ~0.25s at 16k, acceptable latency
            scriptProcessor = audioCtx.createScriptProcessor(4096, 1, 1);

            source.connect(scriptProcessor);
            scriptProcessor.connect(audioCtx.destination); // destination needed for chrome to fire events

            scriptProcessor.onaudioprocess = (e) => {
                if (!ws || ws.readyState !== WebSocket.OPEN) return;

                const inputData = e.inputBuffer.getChannelData(0); // Float32 -1.0 to 1.0

                // Resample if needed
                if (audioCtx.sampleRate !== 16000) {
                    // Simple downsampling
                    const targetData = downsampleBuffer(inputData, audioCtx.sampleRate, 16000);
                    ws.send(targetData.buffer);
                } else {
                    ws.send(inputData.buffer);
                }
            };
        }

        function stopAudioCapture() {
            if (scriptProcessor) {
                scriptProcessor.disconnect();
                scriptProcessor.onaudioprocess = null;
                scriptProcessor = null;
            }
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }
            if (audioCtx) {
                audioCtx.close();
                audioCtx = null;
            }
        }

        // Simple linear interpolation downsampler
        function downsampleBuffer(buffer, sampleRate, outSampleRate) {
            if (outSampleRate === sampleRate) {
                return buffer;
            }
            if (outSampleRate > sampleRate) {
                throw "Downsampling only";
            }
            const sampleRateRatio = sampleRate / outSampleRate;
            const newLength = Math.round(buffer.length / sampleRateRatio);
            const result = new Float32Array(newLength);
            let offsetResult = 0;
            let offsetBuffer = 0;
            while (offsetResult < result.length) {
                const nextOffsetBuffer = Math.round((offsetResult + 1) * sampleRateRatio);
                let accum = 0, count = 0;
                for (let i = offsetBuffer; i < nextOffsetBuffer && i < buffer.length; i++) {
                    accum += buffer[i];
                    count++;
                }
                result[offsetResult] = accum / count;
                offsetResult++;
                offsetBuffer = nextOffsetBuffer;
            }
            return result;
        }

        function generateUUID() {
            return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function (c) {
                var r = Math.random() * 16 | 0, v = c == 'x' ? r : (r & 0x3 | 0x8);
                return v.toString(16);
            });
        }

        function updateTranscriptDisplay(uid, segment) {
            const text = segment.text.trim();
            if (!text) return;

            const startTime = parseFloat(segment.start);
            const key = startTime.toFixed(3).replace('.', '-');
            const divId = `seg-${uid}-${key}`;

            let div = document.getElementById(divId);
            if (!div) {
                div = document.createElement('div');
                div.id = divId;
                div.className = "p-3 bg-gray-700/50 rounded-lg border-l-4 border-blue-500 fade-in mb-3";

                const shortUid = uid.substring(0, 4);

                div.innerHTML = `
                    <div class="text-xs text-gray-400 mb-1 flex justify-between">
                        <span class="font-mono text-blue-300">User ${shortUid}</span>
                        <span>${startTime.toFixed(1)}s</span>
                    </div>
                    <div class="text-lg text-gray-100 leading-relaxed segment-text font-serif"></div>
                `;
                container.appendChild(div);
                container.scrollTop = container.scrollHeight;
            }

            div.querySelector('.segment-text').innerText = text;

            const ph = document.getElementById('placeholder');
            if (ph && ph.style.display !== 'none') ph.style.display = 'none';
        }

        // Set initial mode

    </script>
</body>

</html>